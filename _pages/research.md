---
layout: single
classes: wide
author_profile: false
permalink: /research/
title: "Research"
excerpt: "Minimal Mistakes is a flexible two-column Jekyll theme."
last_modified_at: 2018-06-04T12:04:24-04:00
sidebar:
  nav: "researchnav"

feature_row:
  - image_path: assets/images/researchgraph.png
    alt: "My Research Vision"
    excerpt: "Crowd Computing is a computational paradigm that advocates for the adoption of human intelligence at scale, to improve the performance of machine-based data management systems. 
	<br/><br/>The core idea of Crowd Computing is that some computational tasks are still easier for humans than for machines and algorithms to perform. For instance, image understanding, sarcasm detection, audio transcription, fake news identification, bias identification and detection, and others.
	<br/><br/>Crowd Computing systems are designed to leverage both the scalability of computational machines over large amounts of data as well as the power of human intelligence. As data is typically produced and consumed by humans, it is therefore natural to consider them as first-class citizens in the data life-cycle. 
"
---

{% include feature_row type="left" %}

Crowd Computing advocates for human-in-the-loop systems, where computational tasks are outsourced to a crowd of human individuals or communities, for instance for data creation, analysis, or interpretation purposes.

In recent years, several successful examples have shown the potential and effectiveness of Crowd Computing: Wikipedia, the ESP game, Galaxy Zoo, online labor markets such as Amazon’s Mechanical Turk, the DARPA Balloon Challenge, FoldIt (a protein folding game), Google Maps, Duolingo, Waze, and others. 

At the same time, the Crowd Computing paradigm enabled (and it is enabling) major advances in many fields such as Information Retrieval and Machine Learning, with applications, e.g., to computer vision, natural language understanding. ImageNet is the quintessential example, as its availability is considered to be a major enabler for the “deep learning revolution” of this decade.

### Research Challenges

Despite the successful application of this computational paradigm to a variety of domains, we still have a very poor understanding of Crowd Computing from a design and engineering standpoint. What is missing is a broad theoretical foundation for Crowd Computing, where successful abstractions and well-understood and tested design principles allow the design, creation, and deployment of robust, efficient, and scalable hybrid systems.

My research effort is devoted to the creation of mathematical models and computational methods for Crowd Computing, to address both problems of analysis and design of this class of computational systems.

Involving humans in computation activities is a fundamental scientific challenge that requires obtaining the best from human abilities, while effectively embedding them into traditional computational processes and systems. Examples of the the computer science challenges that are relevant for Crowd Computing systems, and that are currently the object of my research are:
- _Abstractions_: Crowd Computing systems combine traditional computational and networking resources with human intelligence and contributions. The challenge is to define a level of abstraction able to minimally yet exhaustively capture the essential properties of automatic and human computers, and to design and experimentally validate methods able to capture and measure (at scale) “functional” and “non-functional” properties of crowd computing tasks (e.g. granularity, complexity, clarity) human computational units (e.g. expertise, availability, trustworthiness, bias), and crowd computing systems (e.g. batch/stream processing).	
- _Efficiency and Effectiveness_: humans are naturally slower than machines in terms of information processing; also, while machines deterministically compute, humans behavior may be unpredictable, ambiguous, possibly malicious. The challenge is to develop models and methods able to optimally tap human processing in order to minimise computational latency and cost, while maximise the quality, generalisability, and explainability of human processing outcomes. 
- _Sustainability_: human participation is a key constraint for the success and long-term sustainability of Crowd Computing. The challenge is to design and experimentally test different computer-mediated engagement and retainment strategies, based on incentive schemes developed in fields such as behavioral economics and behavioral psychology.

To develop this foundational theory, both mathematical and experimental research is needed. Mathematical models and analysis enable reasoning on Crowd Computing systems’ properties and behavior, so as to enable rigorous design and testing. On the other hand, experimental work is essential to inform the development of such models and to test their validity. In Crowd Computing, requirements are often context and application dependent, and thus not easily amenable to generalization. For instance, my research has shown how people’ traits and behavior manifest differently according to the context (e.g. home, work) and platform (e.g. question answering systems, enterprise social media) of choice, thus often demanding for application-specific modeling methods. Likewise, the application domain of the targeted data calls for different routing and allocation algorithms: several experiments shown us how topic-driven task assignment strategies that are effective in public marketplaces might result less effective in an enterprise environment. This calls for research work in multiple application domains.

### Scientific, Economical, and Societal Relevance

Crowd Computing is a research field in Computer Science that is bound to become increasingly relevant in the
near [future](https://euagenda.eu/publications/ crowd- work- in- europe), as testified by a number of compelling and converging trends.

The recently gained awareness of on line content quality issues combined with the limitation of current artificial intelligence techniques (e.g. the “Fake News” and Russian meddling with election processing) has put Crowd Computing in the spotlight, highlighting its central role in providing reliable, transparent, and safe content exploration and consumption experience.

Several reports project the size of the crowd work market to grow between between $16b and $47 billion by 2020. Gartner [predicts](https://www.gartner.com/events-na/data-analytics/wp-content/uploads/ sites/5/2017/10/Data- and- Analytics- Predictions.pdf) that by 2020, more than 40% of data science tasks will be automated, resulting in increased productivity and broader usage by citizen data scientists; 20% of companies will dedicate workers to monitor and guide neural networks. In recent events, researchers from leading Web companies estimated at around 1 _billion_ dollars the resources spent on an early bases by industries all around the world on human data collection. 

## Team

### Past Team Members


## Projects

### Trompa

### Past Projects